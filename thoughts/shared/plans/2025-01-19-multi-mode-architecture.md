# Multi-Mode Architecture Implementation Plan

## Overview

Refactor the pretty_release_notes project to support three usage modes: (1) as a Python library, (2) as a CLI tool, and (3) as a backend for web frontends. The current monolithic CLI architecture will be transformed into a modular, extensible system with clean separation of concerns.

## Current State Analysis

The pretty_release_notes project is currently a tightly-coupled CLI tool with:
- Business logic intertwined with UI progress reporting
- Global configuration loaded at module import
- Direct threading implementation without abstraction
- No programmatic API for library usage
- CLI-specific dependencies (Typer, Rich) throughout

### Key Discoveries:
- Generator already supports optional UI (`self.ui` checks) - `generator.py:57,63,76`
- Database layer uses abstract base with factory pattern - `database.py:10-133`
- Change protocol enables polymorphic PR/Commit handling - `models/change.py:8-31`
- Configuration passed via constructor injection - `generator.py:17-47`

## Desired End State

A modular architecture where:
- Core business logic has zero CLI dependencies
- Configuration can be provided programmatically or from files
- Progress updates use event-based callbacks
- Library API provides clean, typed interfaces
- Web backend can run async with proper concurrency
- CLI remains fully compatible with existing usage

### Verification:
- Library can be imported and used without CLI dependencies
- Web API can handle concurrent requests safely
- CLI maintains backward compatibility with existing commands

## What We're NOT Doing

- Changing the existing CLI command interface or arguments
- Modifying the GitHub or OpenAI API integration logic
- Altering the release notes generation algorithm
- Replacing the database storage format
- Removing support for current configuration methods

## Implementation Approach

Transform the codebase using the Hexagonal Architecture pattern (Ports & Adapters), where the core business logic is isolated from external concerns. Create clean interfaces (ports) that adapters (CLI, Web, Library) can implement.

## Phase 1: Core Abstractions and Interfaces

### Overview
Create abstract interfaces for all external dependencies and cross-cutting concerns, establishing the foundation for multi-mode support.

### Changes Required:

#### 1. Progress Reporter Interface
**File**: `core/interfaces.py` (new)
**Changes**: Create abstract interface for progress reporting

```python
from abc import ABC, abstractmethod
from typing import Any, Optional
from dataclasses import dataclass

@dataclass
class ProgressEvent:
    type: str  # "info", "success", "error", "markdown"
    message: str
    metadata: dict[str, Any] | None = None

class ProgressReporter(ABC):
    @abstractmethod
    def report(self, event: ProgressEvent) -> None:
        """Report a progress event."""
        pass

class NullProgressReporter(ProgressReporter):
    """No-op reporter for library usage."""
    def report(self, event: ProgressEvent) -> None:
        pass

class CompositeProgressReporter(ProgressReporter):
    """Combine multiple reporters."""
    def __init__(self, reporters: list[ProgressReporter]):
        self.reporters = reporters

    def report(self, event: ProgressEvent) -> None:
        for reporter in self.reporters:
            reporter.report(event)
```

#### 2. Configuration Data Classes
**File**: `core/config.py` (new)
**Changes**: Type-safe configuration with validation

```python
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional

@dataclass
class GitHubConfig:
    token: str
    owner: Optional[str] = None

    def __post_init__(self):
        if not self.token:
            raise ValueError("GitHub token is required")

@dataclass
class OpenAIConfig:
    api_key: str
    model: str = "gpt-4.1"
    max_patch_size: int = 10000

    def __post_init__(self):
        if not self.api_key:
            raise ValueError("OpenAI API key is required")

@dataclass
class DatabaseConfig:
    type: str = "sqlite"
    name: str = "stored_lines"
    enabled: bool = True

    def __post_init__(self):
        if self.type not in ("csv", "sqlite"):
            raise ValueError(f"Invalid database type: {self.type}")

@dataclass
class FilterConfig:
    exclude_change_types: set[str] = field(default_factory=set)
    exclude_change_labels: set[str] = field(default_factory=set)
    exclude_authors: set[str] = field(default_factory=set)

@dataclass
class ReleaseNotesConfig:
    github: GitHubConfig
    openai: OpenAIConfig
    database: DatabaseConfig = field(default_factory=DatabaseConfig)
    filters: FilterConfig = field(default_factory=FilterConfig)
    prompt_path: Path = Path("prompt.txt")
    force_use_commits: bool = False
```

#### 3. Configuration Loader
**File**: `core/config_loader.py` (new)
**Changes**: Multiple strategies for loading configuration

```python
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Dict, Any
from dotenv import dotenv_values
from .config import ReleaseNotesConfig, GitHubConfig, OpenAIConfig, DatabaseConfig, FilterConfig

class ConfigLoader(ABC):
    @abstractmethod
    def load(self) -> ReleaseNotesConfig:
        """Load configuration from source."""
        pass

class DictConfigLoader(ConfigLoader):
    """Load from dictionary (for programmatic usage)."""
    def __init__(self, config_dict: Dict[str, Any]):
        self.config_dict = config_dict

    def load(self) -> ReleaseNotesConfig:
        return ReleaseNotesConfig(
            github=GitHubConfig(
                token=self.config_dict["github_token"],
                owner=self.config_dict.get("github_owner")
            ),
            openai=OpenAIConfig(
                api_key=self.config_dict["openai_api_key"],
                model=self.config_dict.get("openai_model", "gpt-4.1"),
                max_patch_size=self.config_dict.get("max_patch_size", 10000)
            ),
            database=DatabaseConfig(
                type=self.config_dict.get("db_type", "sqlite"),
                name=self.config_dict.get("db_name", "stored_lines"),
                enabled=self.config_dict.get("use_db", True)
            ),
            filters=FilterConfig(
                exclude_change_types=set(self.config_dict.get("exclude_types", [])),
                exclude_change_labels=set(self.config_dict.get("exclude_labels", [])),
                exclude_authors=set(self.config_dict.get("exclude_authors", []))
            ),
            prompt_path=Path(self.config_dict.get("prompt_path", "prompt.txt")),
            force_use_commits=self.config_dict.get("force_use_commits", False)
        )

class EnvConfigLoader(ConfigLoader):
    """Load from .env file (backward compatibility)."""
    def __init__(self, env_path: str = ".env"):
        self.env_path = env_path

    def load(self) -> ReleaseNotesConfig:
        config = dotenv_values(self.env_path)
        return ReleaseNotesConfig(
            github=GitHubConfig(
                token=config["GH_TOKEN"],
                owner=config.get("DEFAULT_OWNER")
            ),
            openai=OpenAIConfig(
                api_key=config["OPENAI_API_KEY"],
                model=config.get("OPENAI_MODEL", "gpt-4.1"),
                max_patch_size=int(config.get("MAX_PATCH_SIZE", "10000"))
            ),
            database=DatabaseConfig(
                type=config.get("DB_TYPE", "sqlite"),
                name=config.get("DB_NAME", "stored_lines"),
                enabled=True
            ),
            filters=FilterConfig(
                exclude_change_types=self._parse_set(config.get("EXCLUDE_PR_TYPES", "")),
                exclude_change_labels=self._parse_set(config.get("EXCLUDE_PR_LABELS", "")),
                exclude_authors=self._parse_set(config.get("EXCLUDE_AUTHORS", ""))
            ),
            prompt_path=Path(config.get("PROMPT_PATH", "prompt.txt")),
            force_use_commits=config.get("FORCE_USE_COMMITS", "false").lower() == "true"
        )

    def _parse_set(self, value: str) -> set[str]:
        return set(value.split(",")) if value else set()
```

### Success Criteria:

#### Automated Verification:
- [x] New core module imports successfully: `env/bin/python3 -c "from core import interfaces, config"`
- [x] Configuration validation works: `env/bin/python3 -c "from core.config import GitHubConfig; GitHubConfig('')"` raises ValueError
- [x] Type checking passes: `env/bin/mypy core/` (Success: no issues found in 4 source files)
- [x] Unit tests pass: `env/bin/pytest tests/test_core.py` (20 tests passed)

#### Manual Verification:
- [x] Configuration classes properly validate input (covered by automated tests)
- [x] Progress reporter interface is extensible (covered by automated tests)
- [x] Config loaders handle edge cases correctly (covered by automated tests)

**Implementation Note**: Phase 1 complete - all verification passed via automated tests.

---

## Phase 2: Business Logic Decoupling

### Overview
Refactor the ReleaseNotesGenerator to use the new abstractions, removing all UI dependencies.

### Changes Required:

#### 1. Update ReleaseNotesGenerator
**File**: `generator.py`
**Changes**: Replace UI calls with progress reporter

```python
from core.interfaces import ProgressReporter, ProgressEvent, NullProgressReporter
from core.config import ReleaseNotesConfig

class ReleaseNotesGenerator:
    def __init__(
        self,
        config: ReleaseNotesConfig,
        progress_reporter: ProgressReporter | None = None,
    ):
        self.config = config
        self.github = GitHubClient(config.github.token)
        self.repository = None
        self.progress = progress_reporter or NullProgressReporter()

        # Store config values
        self.exclude_change_types = config.filters.exclude_change_types
        self.exclude_change_labels = config.filters.exclude_change_labels
        self.exclude_authors = config.filters.exclude_authors
        self.openai_api_key = config.openai.api_key
        self.openai_model = config.openai.model
        self.max_patch_size = config.openai.max_patch_size
        self.prompt_path = config.prompt_path
        self.db_type = config.database.type
        self.db_name = config.database.name
        self.use_db = config.database.enabled
        self.force_use_commits = config.force_use_commits

    def generate(self, tag: str):
        """Generate release notes for a given tag."""
        release = self._get_release(tag)
        old_body = release["body"]

        self.progress.report(ProgressEvent(
            type="markdown",
            message=f"# Current Release Notes\n{old_body}"
        ))

        # Rest of implementation with progress.report() calls
        # instead of self.ui calls
```

#### 2. CLI Progress Adapter
**File**: `adapters/cli_progress.py` (new)
**Changes**: Adapt ProgressReporter to existing CLI class

```python
from core.interfaces import ProgressReporter, ProgressEvent
from ui import CLI

class CLIProgressReporter(ProgressReporter):
    def __init__(self, cli: CLI):
        self.cli = cli

    def report(self, event: ProgressEvent) -> None:
        if event.type == "markdown":
            self.cli.show_markdown_text(event.message)
        elif event.type == "success":
            self.cli.show_success(event.message)
        elif event.type == "error":
            self.cli.show_error(event.message)
        elif event.type == "info":
            self.cli.show_markdown_text(event.message)
        elif event.type == "release_notes":
            heading = event.metadata.get("heading", "Release Notes")
            self.cli.show_release_notes(heading, event.message)
```

#### 3. Update Main Entry Point
**File**: `main.py`
**Changes**: Use new configuration and adapter

```python
from pathlib import Path
import time
import typer
from core.config_loader import EnvConfigLoader
from core.config import ReleaseNotesConfig, FilterConfig
from adapters.cli_progress import CLIProgressReporter
from generator import ReleaseNotesGenerator
from ui import CLI

app = typer.Typer()

@app.command()
def main(
    repo: str,
    tag: str,
    owner: str | None = None,
    database: bool = True,
    prompt_path: Path | None = None,
    force_use_commits: bool = False,
):
    start_time = time.time()

    # Load base config from .env
    loader = EnvConfigLoader()
    config = loader.load()

    # Override with CLI arguments
    if owner:
        config.github.owner = owner
    if prompt_path:
        config.prompt_path = prompt_path
    config.database.enabled = database
    config.force_use_commits = force_use_commits

    # Create UI and adapter
    cli = CLI()
    progress_reporter = CLIProgressReporter(cli)

    # Create generator with config
    generator = ReleaseNotesGenerator(config, progress_reporter)
    generator.initialize_repository(config.github.owner or owner, repo)
    notes = generator.generate(tag)

    cli.show_release_notes("New Release Notes", notes)
    end_time = time.time()
    cli.show_success(f"Generated release notes in {end_time - start_time:.2f} seconds total.")

    if cli.confirm_update():
        generator.update_on_github(notes, tag)

if __name__ == "__main__":
    app()
```

### Success Criteria:

#### Automated Verification:
- [x] CLI still works with same commands: `env/bin/python3 main.py --help`
- [x] Tests still pass: `env/bin/pytest tests/` (20 tests passed)
- [x] No direct UI imports in generator.py: `grep -c "from ui import" generator.py` returns 0
- [x] Type checking passes: `env/bin/mypy generator.py` (pre-existing errors in other files, no new errors)

#### Manual Verification:
- [x] CLI functionality unchanged from user perspective
- [x] Progress messages appear correctly
- [x] Error handling works as before (tested on foreign repo with no permissions)

**Implementation Note**: Phase 2 complete - all verification passed. Ready to proceed to Phase 3.

---

## Phase 3: Library API

### Overview
Create a clean programmatic API for library usage with builder pattern for configuration.

### Changes Required:

#### 1. Library Entry Point
**File**: `pretty_release_notes/__init__.py` (new)
**Changes**: Public API exports

```python
"""Pretty Release Notes - Transform GitHub release notes with AI."""

from .api import ReleaseNotesClient, ReleaseNotesBuilder
from .core.config import (
    ReleaseNotesConfig,
    GitHubConfig,
    OpenAIConfig,
    DatabaseConfig,
    FilterConfig,
)
from .core.interfaces import ProgressReporter, ProgressEvent
from .models import ReleaseNotes, Repository

__version__ = "1.0.0"
__all__ = [
    "ReleaseNotesClient",
    "ReleaseNotesBuilder",
    "ReleaseNotesConfig",
    "GitHubConfig",
    "OpenAIConfig",
    "DatabaseConfig",
    "FilterConfig",
    "ProgressReporter",
    "ProgressEvent",
    "ReleaseNotes",
    "Repository",
]
```

#### 2. Client API
**File**: `api.py` (new)
**Changes**: High-level API for library users

```python
from typing import Optional
from pathlib import Path
from .core.config import ReleaseNotesConfig, GitHubConfig, OpenAIConfig, DatabaseConfig, FilterConfig
from .core.interfaces import ProgressReporter, NullProgressReporter
from .generator import ReleaseNotesGenerator

class ReleaseNotesClient:
    """High-level client for generating release notes."""

    def __init__(
        self,
        config: ReleaseNotesConfig,
        progress_reporter: Optional[ProgressReporter] = None,
    ):
        self.config = config
        self.progress_reporter = progress_reporter or NullProgressReporter()
        self._generator = None

    def generate_release_notes(
        self,
        owner: str,
        repo: str,
        tag: str,
    ) -> str:
        """Generate release notes for a repository and tag.

        Args:
            owner: Repository owner
            repo: Repository name
            tag: Git tag for the release

        Returns:
            Formatted release notes as markdown
        """
        generator = ReleaseNotesGenerator(self.config, self.progress_reporter)
        generator.initialize_repository(owner, repo)
        return generator.generate(tag)

    def update_github_release(
        self,
        owner: str,
        repo: str,
        tag: str,
        notes: str,
    ) -> None:
        """Update release notes on GitHub.

        Args:
            owner: Repository owner
            repo: Repository name
            tag: Git tag for the release
            notes: New release notes content
        """
        generator = ReleaseNotesGenerator(self.config, self.progress_reporter)
        generator.initialize_repository(owner, repo)
        generator.update_on_github(notes, tag)

class ReleaseNotesBuilder:
    """Builder pattern for constructing ReleaseNotesClient."""

    def __init__(self):
        self._github_token = None
        self._openai_key = None
        self._openai_model = "gpt-4.1"
        self._db_type = "sqlite"
        self._db_enabled = True
        self._exclude_types = set()
        self._exclude_labels = set()
        self._exclude_authors = set()
        self._prompt_path = Path("prompt.txt")
        self._progress_reporter = None

    def with_github_token(self, token: str) -> "ReleaseNotesBuilder":
        self._github_token = token
        return self

    def with_openai(self, api_key: str, model: str = "gpt-4.1") -> "ReleaseNotesBuilder":
        self._openai_key = api_key
        self._openai_model = model
        return self

    def with_database(self, db_type: str = "sqlite", enabled: bool = True) -> "ReleaseNotesBuilder":
        self._db_type = db_type
        self._db_enabled = enabled
        return self

    def with_filters(
        self,
        exclude_types: Optional[set[str]] = None,
        exclude_labels: Optional[set[str]] = None,
        exclude_authors: Optional[set[str]] = None,
    ) -> "ReleaseNotesBuilder":
        if exclude_types:
            self._exclude_types = exclude_types
        if exclude_labels:
            self._exclude_labels = exclude_labels
        if exclude_authors:
            self._exclude_authors = exclude_authors
        return self

    def with_prompt_file(self, path: Path) -> "ReleaseNotesBuilder":
        self._prompt_path = path
        return self

    def with_progress_reporter(self, reporter: ProgressReporter) -> "ReleaseNotesBuilder":
        self._progress_reporter = reporter
        return self

    def build(self) -> ReleaseNotesClient:
        """Build the client with configured options.

        Raises:
            ValueError: If required configuration is missing
        """
        if not self._github_token:
            raise ValueError("GitHub token is required")
        if not self._openai_key:
            raise ValueError("OpenAI API key is required")

        config = ReleaseNotesConfig(
            github=GitHubConfig(token=self._github_token),
            openai=OpenAIConfig(
                api_key=self._openai_key,
                model=self._openai_model,
            ),
            database=DatabaseConfig(
                type=self._db_type,
                enabled=self._db_enabled,
            ),
            filters=FilterConfig(
                exclude_change_types=self._exclude_types,
                exclude_change_labels=self._exclude_labels,
                exclude_authors=self._exclude_authors,
            ),
            prompt_path=self._prompt_path,
        )

        return ReleaseNotesClient(config, self._progress_reporter)
```

#### 3. Example Library Usage
**File**: `examples/library_usage.py` (new)
**Changes**: Document library usage patterns

```python
"""Example of using pretty_release_notes as a library."""

from pretty_release_notes import ReleaseNotesBuilder, ProgressReporter, ProgressEvent

class CustomProgressReporter(ProgressReporter):
    """Custom progress reporter that logs to console."""

    def report(self, event: ProgressEvent) -> None:
        print(f"[{event.type}] {event.message}")

# Build client with configuration
client = (
    ReleaseNotesBuilder()
    .with_github_token("ghp_xxxxx")
    .with_openai("sk-xxxxx", model="gpt-4")
    .with_database("sqlite", enabled=True)
    .with_filters(
        exclude_types={"chore", "refactor", "ci"},
        exclude_labels={"skip-release-notes"},
        exclude_authors={"dependabot[bot]"},
    )
    .with_progress_reporter(CustomProgressReporter())
    .build()
)

# Generate release notes
notes = client.generate_release_notes(
    owner="frappe",
    repo="erpnext",
    tag="v15.38.4",
)

print(notes)

# Optionally update GitHub
# client.update_github_release("frappe", "erpnext", "v15.38.4", notes)
```

### Success Criteria:

#### Automated Verification:
- [x] Library imports work: `env/bin/python3 -c "import sys; sys.path.insert(0, '.'); from api import ReleaseNotesBuilder"`
- [x] Builder pattern works: `env/bin/python3 examples/library_usage.py` (with valid tokens)
- [x] Type hints are correct: `env/bin/mypy --follow-imports=skip api.py`
- [x] No CLI dependencies: `env/bin/python3 -c "import sys; sys.path.insert(0, '.'); from api import ReleaseNotesBuilder; assert 'typer' not in sys.modules"`

#### Manual Verification:
- [x] Library API is intuitive and well-documented
- [x] Progress reporting works with custom reporters (covered by automated tests)
- [x] Configuration validation provides helpful errors (covered by automated tests)

**Implementation Note**: Phase 3 complete - all verification passed. 19 new automated tests added to `tests/test_api.py` covering progress reporting and configuration validation. The `__init__.py` at root was removed for cleaner imports during development; it will be added back in Phase 6 for package distribution.

---

## Phase 4: Concurrent Execution Support

### Overview
Add thread-safe execution and prepare for async/web usage by abstracting the threading implementation.

### Changes Required:

#### 1. Execution Strategy Interface
**File**: `core/execution.py` (new)
**Changes**: Abstract execution strategies

```python
from abc import ABC, abstractmethod
from typing import Callable, List, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

class ExecutionStrategy(ABC):
    """Abstract strategy for parallel execution."""

    @abstractmethod
    def execute_parallel(
        self,
        tasks: List[Callable[[], Any]],
    ) -> List[Any]:
        """Execute tasks in parallel and return results."""
        pass

class ThreadingStrategy(ExecutionStrategy):
    """Original threading implementation."""

    def execute_parallel(
        self,
        tasks: List[Callable[[], Any]],
    ) -> List[Any]:
        threads = []
        results = [None] * len(tasks)

        def run_task(index: int, task: Callable[[], Any]):
            results[index] = task()

        for i, task in enumerate(tasks):
            thread = threading.Thread(target=run_task, args=(i, task))
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        return results

class ThreadPoolStrategy(ExecutionStrategy):
    """Thread pool implementation for better resource management."""

    def __init__(self, max_workers: int = 10):
        self.max_workers = max_workers

    def execute_parallel(
        self,
        tasks: List[Callable[[], Any]],
    ) -> List[Any]:
        results = []
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [executor.submit(task) for task in tasks]
            for future in as_completed(futures):
                results.append(future.result())
        return results

class SequentialStrategy(ExecutionStrategy):
    """Sequential execution for debugging or environments without threading."""

    def execute_parallel(
        self,
        tasks: List[Callable[[], Any]],
    ) -> List[Any]:
        return [task() for task in tasks]
```

#### 2. Update Generator with Execution Strategy
**File**: `generator.py`
**Changes**: Use execution strategy instead of direct threading

```python
from core.execution import ExecutionStrategy, ThreadPoolStrategy

class ReleaseNotesGenerator:
    def __init__(
        self,
        config: ReleaseNotesConfig,
        progress_reporter: ProgressReporter | None = None,
        execution_strategy: ExecutionStrategy | None = None,
    ):
        # ... existing init code ...
        self.execution = execution_strategy or ThreadPoolStrategy()

    def _get_prs_for_lines(self, lines: list["ReleaseNotesLine"]):
        """Download info for all PRs in parallel."""
        tasks = []
        for line in lines:
            if line.pr_no and not line.is_new_contributor:
                tasks.append(lambda l=line: self._get_pr_for_line(l))

        self.execution.execute_parallel(tasks)

    def _process_lines(self, lines: list["ReleaseNotesLine"]):
        """Process all lines in parallel."""
        tasks = [
            lambda l=line: self._process_line(l)
            for line in lines
        ]
        self.execution.execute_parallel(tasks)
```

#### 3. Thread-Safe Database Access
**File**: `database.py`
**Changes**: Add connection pooling for SQLite

```python
import threading
from contextlib import contextmanager

class SQLiteDatabase(Database):
    _local = threading.local()

    def __init__(self, path: Path):
        self.path = path
        self._lock = threading.Lock()

    @property
    def connection(self):
        """Thread-local database connection."""
        if not hasattr(self._local, "conn"):
            self._local.conn = sqlite3.connect(self.path)
            self._local.cursor = self._local.conn.cursor()
            self._create_table()
        return self._local.conn

    @property
    def cursor(self):
        """Thread-local cursor."""
        _ = self.connection  # Ensure connection exists
        return self._local.cursor

    @contextmanager
    def transaction(self):
        """Context manager for transactions."""
        with self._lock:
            try:
                yield self.cursor
                self.connection.commit()
            except Exception:
                self.connection.rollback()
                raise
```

### Success Criteria:

#### Automated Verification:
- [x] Thread pool execution works: `env/bin/pytest tests/test_execution.py` (12 tests passed)
- [x] Database is thread-safe: `env/bin/pytest tests/test_database_threading.py` (7 tests passed)
- [x] No deadlocks with concurrent access: Covered by `test_no_deadlocks_under_load` test
- [x] Performance is maintained: Verified by `test_parallel_faster_than_sequential` test

#### Manual Verification:
- [x] Multiple concurrent generations work correctly (tested on release with 35 PRs)
- [x] Resource usage is reasonable under load (tested with and without --no-database flag)
- [x] No race conditions or data corruption (verified working as expected)

**Implementation Note**: Phase 4 complete - all verification passed. Thread pool strategy with max_workers=10 provides better resource management than direct threading. Database thread-safety ensures no conflicts during concurrent operations. Ready to proceed to Phase 5.

---

## Phase 5: Web Backend Support

### Overview
Add REST API endpoints using FastAPI for web frontend integration.

### Changes Required:

#### 1. FastAPI Application
**File**: `web/app.py` (new)
**Changes**: REST API endpoints

```python
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any
import uuid
from datetime import datetime

from pretty_release_notes import ReleaseNotesBuilder
from core.interfaces import ProgressReporter, ProgressEvent

app = FastAPI(title="Pretty Release Notes API", version="1.0.0")

# In-memory job storage (use Redis in production)
jobs: Dict[str, Dict[str, Any]] = {}

class GenerateRequest(BaseModel):
    owner: str
    repo: str
    tag: str
    github_token: str
    openai_key: str
    openai_model: str = "gpt-4.1"
    exclude_types: list[str] = []
    exclude_labels: list[str] = []
    exclude_authors: list[str] = []

class JobResponse(BaseModel):
    job_id: str
    status: str
    created_at: datetime
    completed_at: Optional[datetime] = None
    result: Optional[str] = None
    progress: list[Dict[str, Any]] = []
    error: Optional[str] = None

class WebProgressReporter(ProgressReporter):
    """Store progress events for web clients."""

    def __init__(self, job_id: str):
        self.job_id = job_id
        self.events = []

    def report(self, event: ProgressEvent) -> None:
        self.events.append({
            "timestamp": datetime.now().isoformat(),
            "type": event.type,
            "message": event.message,
            "metadata": event.metadata,
        })
        # Update job progress
        if self.job_id in jobs:
            jobs[self.job_id]["progress"] = self.events

@app.post("/generate", response_model=JobResponse)
async def generate_release_notes(
    request: GenerateRequest,
    background_tasks: BackgroundTasks,
):
    """Start release notes generation job."""
    job_id = str(uuid.uuid4())

    # Create job record
    jobs[job_id] = {
        "id": job_id,
        "status": "pending",
        "created_at": datetime.now(),
        "request": request.dict(),
        "progress": [],
        "result": None,
        "error": None,
    }

    # Start background task
    background_tasks.add_task(
        process_generation,
        job_id,
        request,
    )

    return JobResponse(
        job_id=job_id,
        status="pending",
        created_at=jobs[job_id]["created_at"],
    )

async def process_generation(job_id: str, request: GenerateRequest):
    """Process generation in background."""
    jobs[job_id]["status"] = "running"

    try:
        # Build client
        progress_reporter = WebProgressReporter(job_id)
        client = (
            ReleaseNotesBuilder()
            .with_github_token(request.github_token)
            .with_openai(request.openai_key, request.openai_model)
            .with_filters(
                exclude_types=set(request.exclude_types),
                exclude_labels=set(request.exclude_labels),
                exclude_authors=set(request.exclude_authors),
            )
            .with_progress_reporter(progress_reporter)
            .build()
        )

        # Generate notes
        result = client.generate_release_notes(
            request.owner,
            request.repo,
            request.tag,
        )

        # Update job
        jobs[job_id].update({
            "status": "completed",
            "completed_at": datetime.now(),
            "result": result,
        })

    except Exception as e:
        jobs[job_id].update({
            "status": "failed",
            "completed_at": datetime.now(),
            "error": str(e),
        })

@app.get("/jobs/{job_id}", response_model=JobResponse)
async def get_job_status(job_id: str):
    """Get job status and result."""
    if job_id not in jobs:
        raise HTTPException(status_code=404, detail="Job not found")

    job = jobs[job_id]
    return JobResponse(
        job_id=job_id,
        status=job["status"],
        created_at=job["created_at"],
        completed_at=job.get("completed_at"),
        result=job.get("result"),
        progress=job.get("progress", []),
        error=job.get("error"),
    )

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy"}
```

#### 2. Web Server Runner
**File**: `web/server.py` (new)
**Changes**: Uvicorn server configuration

```python
import uvicorn
from web.app import app

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
    )
```

#### 3. Web Requirements
**File**: `requirements-web.txt` (new)
**Changes**: Additional dependencies for web backend

```txt
fastapi>=0.119.0
uvicorn>=0.38.0
pydantic>=2.0.0
```

### Success Criteria:

#### Automated Verification:
- [x] API starts successfully: `env/bin/python3 -m uvicorn web.app:app --host 0.0.0.0 --port 8000`
- [x] Health check works: `curl http://localhost:8000/health`
- [x] OpenAPI docs available: `curl http://localhost:8000/docs`
- [x] Job creation works: `curl -X POST http://localhost:8000/generate -H "Content-Type: application/json" -d '{"owner":"test","repo":"test","tag":"v1.0.0","github_token":"xxx","openai_key":"xxx"}'`

#### Manual Verification:
- [x] Job status updates correctly during generation
- [x] Progress events are captured
- [x] Error handling works properly (OpenAI errors now reported in progress events)
- [x] Concurrent requests are handled correctly (tested with 3 concurrent jobs, all completed successfully)

**Implementation Note**: After completing this phase and automated verification passes, pause for API testing confirmation before proceeding to Phase 6.

---

## Phase 6: CLI Backward Compatibility

### Overview
Ensure the CLI maintains full backward compatibility while using the new architecture.

### Changes Required:

#### 1. Update CLI Imports
**File**: `main.py`
**Changes**: Minimal changes to maintain compatibility

```python
#!/usr/bin/env python
"""Pretty Release Notes CLI - Backward compatible entry point."""

from pathlib import Path
import time
import typer
import sys
import os

# Add project root to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from core.config_loader import EnvConfigLoader
from adapters.cli_progress import CLIProgressReporter
from generator import ReleaseNotesGenerator
from ui import CLI

app = typer.Typer()

@app.command()
def main(
    repo: str,
    tag: str,
    owner: str | None = None,
    database: bool = True,
    prompt_path: Path | None = None,
    force_use_commits: bool = False,
):
    """Generate pretty release notes for a GitHub repository.

    This command maintains full backward compatibility with the original CLI.
    """
    # Implementation remains the same as Phase 2
    # ... existing implementation ...

if __name__ == "__main__":
    app()
```

#### 2. pyproject.toml for Package Distribution
**File**: `pyproject.toml` (new)
**Changes**: Modern Python package configuration

```toml
[build-system]
requires = ["setuptools>=68.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "pretty-release-notes"
version = "1.0.0"
description = "Transform GitHub release notes with AI"
readme = "README.md"
requires-python = ">=3.11"
license = {text = "MIT"}
authors = [
    {name = "Your Name", email = "your.email@example.com"}
]
keywords = ["github", "release-notes", "openai", "cli"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Documentation",
    "Topic :: Text Processing :: Markup :: Markdown",
]

dependencies = [
    "typer>=0.9.0",
    "rich>=13.0.0",
    "requests>=2.31.0",
    "openai>=1.0.0",
    "python-dotenv>=1.0.0",
    "tenacity>=8.2.0",
]

[project.optional-dependencies]
web = [
    "fastapi>=0.119.0",
    "uvicorn>=0.38.0",
    "pydantic>=2.0.0",
]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "mypy>=1.7.0",
    "ruff>=0.1.0",
]

[project.scripts]
pretty-release-notes = "main:app"

[project.urls]
Homepage = "https://github.com/yourusername/pretty_release_notes"
Documentation = "https://github.com/yourusername/pretty_release_notes#readme"
Repository = "https://github.com/yourusername/pretty_release_notes"
Issues = "https://github.com/yourusername/pretty_release_notes/issues"

[tool.setuptools]
packages = ["pretty_release_notes", "core", "adapters", "web", "models"]

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.format]
# Use ruff for formatting (replaces black)
quote-style = "double"
indent-style = "tab"

[tool.ruff.lint]
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "N",   # pep8-naming
    "UP",  # pyupgrade
]
ignore = []

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
disallow_incomplete_defs = false
check_untyped_defs = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "--cov=. --cov-report=html --cov-report=term-missing"
```


### Success Criteria:

#### Automated Verification:
- [x] Original CLI commands work: `env/bin/python3 main.py --help`
- [x] Package installs correctly: `env/bin/pip install -e .`
- [x] Console script works: `env/bin/pretty-release-notes --help`
- [x] All original tests pass: `env/bin/pytest tests/` (77 tests passed)
- [x] No breaking changes: Only added shebang, docstring, and py-modules to pyproject.toml

#### Manual Verification:
- [x] Existing .env configurations still work
- [x] All CLI flags function as before
- [x] Output format unchanged
- [x] Performance comparable to original

**Implementation Note**: Phase 6 complete - all verification passed. Requirements files removed in favor of pyproject.toml dependency management.

---

## Testing Strategy

### Unit Tests:
- Test new configuration classes and validation
- Test progress reporter implementations
- Test execution strategies
- Test API endpoints

### Integration Tests:
- Test CLI with real GitHub/OpenAI APIs
- Test library API end-to-end
- Test web API with concurrent requests
- Test database thread safety

### Manual Testing Steps:
1. Run CLI with existing .env file
2. Generate notes for a real repository
3. Use library API programmatically
4. Test web API with multiple concurrent requests
5. Verify backward compatibility with existing scripts

## Performance Considerations

- Thread pool size tuned for optimal performance (10 workers default)
- Database connections are thread-local to avoid contention
- Web API uses background tasks for non-blocking operation
- Configuration validation happens once at startup

## Migration Notes

- Existing users can continue using the CLI without any changes
- New library users should use the builder pattern for configuration
- Web API users need additional dependencies (install with `[web]` extra)
- Database format remains unchanged

## References

- Original architecture analysis: Research conducted in this session
- Design patterns: Hexagonal Architecture (Ports & Adapters)
- Python typing: PEP 484, 526, 544 (Protocols)
- Threading best practices: Python concurrent.futures documentation